# Как понять,что HC переобучена --- когда на графике точность в выборке train и выборки валидации начинают расходиться(момент когда начинают расходиться 
# начало переобучения)

# Рекомендации по борьбе с переобучением 
# 1.Рекомендация : если наблюдается расхождение в точности выходных значений между обучающей и проверочной 
# выборками, то процесс обучения следует остановить и уменьшить число нейронов(также может уменьшить качество).


# Метод Dropout
# Он с какой-либо вероятностью p отключает нейроны в HC и добавляет к остальным нейронам значение 'S' , которое заменяет старые нейроны.
# p_i - вероятность отключения нейрона 
# x_i - число нейронов 
# Мат.ожидание = x_i * p  -> n(количество нейронов) * p -> По итогу мы получаем выключеные нейроны
# n - n*p == n * (1 - p) == n * q(вероятность того,что нейрон будет включен) -> Число нейронов,которые включены 
# x_q(число вкл нейронов после выкл) / x(все нейроны) == n * q / n == q -> вероятность того,что нейрон будет включен
# x_q * 1/q == x -> Так,чтобы все нейроны были включены 
# Короче говоря x_q(количество нейронов после выключения) нужно умножить на 1/q , чтобы получить выход в нейроне,равном нейрону без выключения

# 2.Рекомендация: если наблюдается переобучение и сокращение числа нейронов недопустимо(по тем или иным причинам),то следует попробовать метод Dropout
# 
# Авторы подхода рекомендуют сначала попробовать вероятность выключения = 0.5,потом 0.4,0.3

Dense(300,activation = 'relu')
Dropout(0.5) # идет сразу после слоя нейрона,чтобы относиться именно к нему 
